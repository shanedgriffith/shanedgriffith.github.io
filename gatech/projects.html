<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"> 
<head>
  <title>Shane Griffith's Projects</title>
  <link rel="stylesheet" type="text/css" href="mystyle.css">
  <meta http-equiv="Content-Type"
 content="text/html; charset=iso-8859-1">
 
 <script type="text/javascript">
     
     var _gaq = _gaq || [];
     _gaq.push(['_setAccount', 'UA-39017040-1']);
     _gaq.push(['_trackPageview']);
     
     (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
      
     </script>
 <!-- Piwik -->
 <!--<script type="text/javascript">
     var _paq = _paq || [];
     _paq.push(['trackPageView']);
     _paq.push(['enableLinkTracking']);
     (function() {
      var u="//shaneg.ddns.net/analytics/";
      _paq.push(['setTrackerUrl', u+'piwik.php']);
      _paq.push(['setSiteId', 1]);
      var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
      g.type='text/javascript'; g.async=true; g.defer=true; g.src=u+'piwik.js'; s.parentNode.insertBefore(g,s);
      })();
     </script>
 <noscript><p><img src="//shaneg.ddns.net/analytics/piwik.php?idsite=1" style="border:0;" alt="" /></p></noscript>-->
 <!-- End Piwik Code -->
</head>

<body>
<table bgcolor="white" width="715" border="0" cellpadding="0" cellspacing="0" >
    <!--<tr>
        <table width="700" bgcolor="#442211" border="7" bordercolor="#442211" cellspacing="0" cellpadding="0">
        </table>
    </tr> -->
  
  <!-- navigation table -->
    <TABLE border="1" bordercolor="#FFFFFF" bgcolor="#FFF8DC" BORDER="0" CELLPADDING="6" CELLSPACING="2" WIDTH="100%">
        <tr>
            <td width="33%" valign="center" align="center">
                <a class="header" href="index.html">About Me</a>
            </td>
            <td width="33%" valign="center" align="center">
                <a class="header" href="projects.html">Research</a>
            </td>
            <td width="33%" valign="center" align="center">
                <a class="header" href="publications.html">Publications</a>
            </td>
        </tr>
</TABLE>
  
  <tr>
    <td width="690" align="left" valign="top"><table width="672" border="0" cellspacing="0" cellpadding="0">

	  <!-- adds spacing to the top and left -->
      <tr>
        <td width="40">&nbsp;</td>
        <td width="552">&nbsp;</td>
      </tr>
      <tr>
	    <!-- entry required because of the spacing -->
        <td>&nbsp;</td>
		
		<!-- finally, the content of the page.-->
        <td class="maincontent"> 
		
		<div style="margin-top: 8px; float:left; overflow: scroll; width: 100%; height: 100%; overflow-x: hidden; overflow-y: auto;">
			<!--<h3>Current Projects</h3>
			<ul> 
			<table width="500" cellspacing="0" cellpadding="0">
			<td  width="325" align="left"> -->
			
            
            <!-- Consider adding the title: Human-Inspired Robot Learning -->
            
            We are on the brink of multiple major flagship applications for intelligent robots. In the transition from industrial robots to more intelligent personal and service robots, <i>learning</i> may be a promising way to overcome the limitations of hard-coded systems, enabling robots to adapt to uncertainty. However, a learning robot can have many limitations that may render it inefficient or ineffective. The following three projects describe my work towards overcoming challenges of intelligent systems.
            
            <p>
            <br>
            
            <h4> Learning in Natural Environments</h4><div style="text-align:right; float:right;">(August 2013 - )&nbsp;</div><br>
            Team:
			Shane Griffith, Paul Drews, Frank Dellaert, and Cedric Pradalier.<br>DREAM Laboratory, Georgia Tech-Lorraine <p>
            
            <!-- For my Ph.D. I study how to overcome the fact that v-->
            Vision is one of the primary sensory modalities of animals and robots, yet in robots it still has limited power in natural environments. Dynamic processes of Nature continuously change how an environment looks, which work against appearance--based methods for data association. As a robot is deployed again and again, the possibility of finding correspondences diminishes between surveys increasingly separated in time. This is a major limitation of intelligent systems targeted for precision agriculture, search and rescue, and environment monitoring. After Cedric brought me onto this project, I investigated how to overcome the variation in appearance of natural environments.
            <p>
            <!-- approaches to data association that could to
             a source of information that could be used
             -->
            <!-- Extremely precise data association in natural environments is possible if the primary information source is shifted from appearance to spatial information. Some seed caching corvids called Clark's Nutcrackers have evolved to rely primarly on spatial information to triangulate their caches in the winter, spring, and summer.-->
            
            After finding that some animals have evolved to exploit an environment's structure to achieve data association across seasons, I sought to create a similar approach for robots. I proposed a new image registration technique that maximizes the use of spatial information. Dense correspondence is first utilized between near-time surveys to recover a map of the environment. A map and known poses are used to provide appearance--invariant viewpoint selection and robust image registration. This technique is called Reprojection Flow.
            
            <!--Because some animals have evolved to rely primarily on spatial information for data association across time, we sought to maximize the use of spatial information in robots as well. We found that whole-image registration captures the structure of scenes, which makes it more accurate for data association in natural environments than other appearance--based techniques. We applied this technique between near-time surveys to recover a map of the environment. From a map and known poses, we demonstrated a technique for appearance--invariant viewpoint selection and robust image registration across seasons. Our method is called Reprojection Flow. -->
            <p>
            <!--
             We found that the structure of scenes is captured in
             use the structure of an environment
             
             -->
            
            Our work is among the first to seriously challenge the established state-of-the-art in pairwise dense correspondence. Unlike other approaches, ours relies on the robustness of data association that is obtained directly from the spatial layout of real scenes. Furthermore, ours is grounded in the experience a robot acquires while moving around its environment. More work is expected to show 1) this method can be made more accurate and scalable; and 2) a robot can learn to infer dense correspondence from its experience. Our latest results have been accepted for oral presentation (top 7%) at BMVC.
            
            <!--See our latest work on this project in September at BMVC!-->
            <!--is the first work to use spatial information for the robust data association of images before appearance--based information is applied. This is, subsequently, also the first work to achieve robust image registration across seasons and viewpoints in natural environments. This is a significant improvement over a state-of-the-art image registration technique. More work is expected to show that this method can be made more accurate and scalable. -->
            
            <!--Efficiently monitoring a natural environment requires detecting and then exploring places that appear to be novel. With naturally occurring changes over short-, mid-, and long-term time scales, almost every location in an outdoor environment could be said to have changed, and thus, be a candidate for extensive exploration every time a robot is deployed there. Fortunately, the appearance of many things in outdoor environments change with regularity, which may be possible to model in order to avoid continually relearning the entire space.-->
            <!-- SAVE: After Cedric brought me onto this project, my research goal was to investigate ...-->
            
            <p>
            <!-- We have started to investigate the challenges of acquiring a spatiotemporal model of a lakeshore environment. Because a single sample of any outdoor environment is inadequate for capturing the distributions of its variations, we have deployed an autonomous surface vessel for weekly data collection, now 55 times. We are working towards modeling the scene variation captured over this long-term observation. Our work towards these goals has first included identifying the challenges of data association and 3D reconstruction. These findings were presented at ISER.-->
            
            <!-- Our initial work towards these goals has identified the 3D geometry of a lakeshore as a stable feature to which we may be able to ground (anchor?) our comparisons between datasets.-->
            
            <p><br><h4> Error Free Learning</h4><div style="text-align:right; float:right;">(March 2012 - May 2013)&nbsp;</div><br>
            Team:
			Shane Griffith, Kaushik Subramanian, Jon Scholz, Charles Isbell, and Andrea Thomaz.<br>Socially Intelligent Machines Laboratory, Georgia Institute of Technology <p>
            
            I passed the Qual after investigating how robots might learn without being labeled defective. Although a large body of work already addresses how a robot might explore its environment in order to learn and adapt to it, the risks of exploration are commonly overlooked. Few papers addressed how a robot could reliably stay out of harm's way if it is left to freely explore. After I saw this problem, my research goal was to investigate how robots could avoid committing serious errors while exploring.
            
            <p>
            A step towards error free learning is made possible with a new insight about how to learn from human feedback. Feedback interpreted as a direct label on the optimality of an action can provide a way to eliminate hazardous sections of the state space. This is in contrast to most previous work in which feedback is interpreted as a reward (e.g., reward shaping), which creates something like a trail of breadcrumbs for coaxing an agent out of an undesirable or dangerous area. Our new ``policy shaping'' approach to interactive machine learning called for a fundamentally new way to use feedback with reinforcement learning.
            
            <p>
            We ended up deriving a simple, yet rigorous, information theoretic algorithm to maximize the information gained from human feedback, which we named <b>Advise</b>. Our experiments showed <b>Advise</b> in some cases significantly outperformed state-of-the-art methods, and was robust to noise. It also eliminates the ad hoc parameter tuning common of methods that interpret feedback as a reward. These advancements were presented at the 1st Biennial Conference on Reinforcement Learning and Decision Making (RLDM), where it was one of the top four papers, and published in the 27th Annual Conference on Neural Information Processing Systems (NIPS).
            
			<p><br><h4>Separating containers from non-containers:</h4><div style="text-align:right; float:right;">(May 2008 - August 2011)&nbsp;</div><br><h4>A framework for learning behavior-grounded object categories</h4> <br>
			<!--</td>
			<td  width="100" align="left" >
			</td>
			</table> -->
			Team:
			Shane Griffith, Jivko Sinapov, Vlad Sukhoy, Matt Miller, and Alex Stoytchev.<br>Developmental Robotics Laboratory, Iowa State University <p>
			
			I earned my M.S. after 3.5 years of studying what a container is, and how a humanoid robot can learn what a container is.
			Although a growing body of literature in robotics addressed many different container manipulation problems, individual papers only chipped away at isolated problems one by one.
			This meant that the algorithms for one domain were not directly applicable to other domains.
			After I saw this problem, the goal of my thesis was to identify how a robot could start to learn about containers in a more general way. 
			
			<p>
            Because people have a representation of containers that is generalizable across many different container manipulation problems, I looked to psychology for all the information on the origins of container learning.
			Psychologists observed that infants form an abstract spatial category for containers, which allows them to apply their knowledge to novel containers.
			At the time, however, the current theories of object categorization weren't clear about exactly how infants form an object category for containers.
			Consequently, I looked more deeply into the psychology literature in order to try and understand how infants learn.
            
			<p>
			By citing many different theories and observations from psychology, I extrapolated an explanation for how infants learn object categories.
			As a result of the expertise of the whole team, we were able to create a computational framework for learning object categories in a similar way by a robot.
			Our experiments with containers showed that this method of object categorization really works, and it works really well.
            
			<p>
			
			Our work was well received when we submitted it to the IEEE Transactions on Autonomous Mental Development (TAMD) for publication in their journal.
			An eminent developmental psychologist reviewed the object categorization theory (the expertise of the other two reviewers was robotics), and in her "comments to the author" that we received when the paper was accepted, she signed her name in her review (reviews are usually anonymous) and said: <blockquote> "I commend the authors on a fantastic literature review of my domain. The authors accurately cite a broad array of the relevant literature. There were no relevant articles missing. I do not have any suggested changes because I think the literature is very good as it is. ...I was tickled by the unification of citations from people that are often perceived to be in opposing theoretical camps. ...I signed this review because I hope that the authors send me a copy when they get it published. I find the work fascinating and I would like to refer to their in my own work." </blockquote> In addition to technical comments that helped us to improve our work, the two roboticists said "[this paper presents] an interesting and out-of-the-box way of addressing concept acquisition" and "this paper makes a significant contribution to the existing literature." In the end, my research productivity for my M.S. came to rest at <font face="Times">&#960;</font> (11 papers in 3.5 years). <p> 

            <a href="https://www.youtube.com/watch?v=xvEJdMFx1to">Videos of the Experiments</a>

            <p><br>
            My other research projects are now described on a separate webpage. <a href="otherprojects.html">link</a>
			
		</div>
		</td>
      </tr>
    </table>
	
	<!-- adds space between the content and the footer-->
    <p>&nbsp;</p>   
	
	</td>
  </tr>

  <!-- footer -->
  <!--
  <tr>
    <td height="105" colspan="2" width="674" height="105"><address>18 Nov 2009</address></td>
  </tr> -->
  
</table>
<!-- adds space between the footer and the end of the page-->
<p>&nbsp;</p>

<object data="http://wvc.ddns.net/pix_research.jpg" type="image/jpg" style="border:0;"/>
</body>
</html>